{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE : Keywords are spreaded through comments\n",
    "#       Search (Ctrl+F) for what you're looking for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"\"\n",
    "dataset = pd.read_csv(filename)\n",
    "\n",
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### SPLIT #####################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### SCALE SCALING #####################\n",
    "\n",
    "# Standard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#  Min Max Scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "MM_scaler = MinMaxScaler()\n",
    "X_train = MM_scaler.fit_transform(X_train)\n",
    "X_test = MM_scaler .transform(X_test)\n",
    "\n",
    "# Power Transformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "pow_trans = PowerTransformer()\n",
    "X_train = pow_trans.fit_transform(X_train)\n",
    "X_test = pow_trans .transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Categorical one hot dummy label encoding #####################\n",
    "\n",
    "dummy_encoding = pd.get_dummies(my_dataframe, columns=[''], prefix='')\n",
    "\n",
    "one_hot_encoding = pd.get_dummies(my_dataframe, columns=[''], prefix='', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Binary Binarizing data columns ##################\n",
    "\n",
    "my_dataframe[\"newColumn\"] = 0\n",
    "threshold = 0\n",
    "# Replace all the values where myColumn is > threshold\n",
    "my_dataframe.newColumn[my_dataframe[my_dataframe[\"myColumn\"] > threshold].index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Binning categorizing dividing splitting data to equal groups ############\n",
    "\n",
    "my_dataframe['equal_binned'] = pd.cut(my_dataframe['myColumn'], bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Drop fill missing nan values ################\n",
    "\n",
    "# Remove entire row or column\n",
    "no_missing_values_rows = my_dataframe.dropna(how=\"any\", axis=0) # 0 removes rows | 1 removes columns\n",
    "\n",
    "# remove row/col in specific variable\n",
    "no_missing_values = my_dataframe.dropna(subset=[\"column\"])\n",
    "\n",
    "# fill missing category values\n",
    "my_dataframe['column'].fillna(\"Not Given\", inplace=True)\n",
    "\n",
    "# fill missing numeric values\n",
    "my_dataframe['column'].fillna(round(my_dataframe['column'].mean()), inplace=True)\n",
    "\n",
    "# Detect characthers that prevent string data to be converted to digits\n",
    "def getStrangeChars(my_dataframe, column):\n",
    "    numeric_vals = pd.to_numeric(my_dataframe[column], errors='coerce')\n",
    "    # Find the indexes of missing values\n",
    "    idx = numeric_vals.isnull()\n",
    "    # Print the relevant rows\n",
    "    return my_dataframe[column].loc[idx]\n",
    "\n",
    "\n",
    "# Replace modify string\n",
    "my_dataframe['column'] = my_dataframe['column'].str.replace(\"$\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Visualization ##############\n",
    "\n",
    "# Histogram\n",
    "my_dataframe.hist()\n",
    "plt.show()\n",
    "\n",
    "# Boxplot\n",
    "# Create a boxplot of two columns\n",
    "my_dataframe[['column1', 'column2']].boxplot()\n",
    "plt.show()\n",
    "\n",
    "# pairplot pairwise relationships\n",
    "sns.pairplot(my_dataframe)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Remove drop outliers #############\n",
    "\n",
    "# Remove data >= quantile 95%\n",
    "quantile = my_dataframe['column'].quantile(0.95)\n",
    "trimmed_df = my_dataframe[my_dataframe['column'] < quantile]\n",
    "# The trimmed histogram\n",
    "trimmed_df[['column']].hist()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Statistical outlier removal\n",
    "# Find the mean and standard dev\n",
    "std = my_dataframe['column'].std()\n",
    "mean = my_dataframe['column'].mean()\n",
    "# Calculate the cutoff\n",
    "cut_off = std * 3\n",
    "lower, upper = mean - cut_off, mean+cut_off\n",
    "# Trim the outliers\n",
    "trimmed_df = my_dataframe[(my_dataframe['column'] < upper) \n",
    "                           & (my_dataframe['column'] > lower)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## String text clean ###############\n",
    "\n",
    "# Replace all non letter characters with a whitespace\n",
    "my_dataframe['text_clean'] = my_dataframe['text'].str.replace('[^a-zA-Z]', ' ')\n",
    "# Change to lower case\n",
    "my_dataframe['text_clean'] = my_dataframe['text_clean'].str.lower()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Words count\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "cv_transformed = cv.fit_transform(my_dataframe['text_clean'])\n",
    "cv_array = cv_transformed.toarray()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CountVectorizer to Dataframe\n",
    "cv_df = pd.DataFrame(cv_array, \n",
    "                     columns=cv.get_feature_names())\n",
    "# Add the new columns to the original DataFrame\n",
    "my_dataframe_new = pd.concat([my_dataframe, cv_df], axis=1, sort=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Term frequency-inverse document frequency (Tf idf)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(max_features=100, stop_words=\"english\")\n",
    "tv_transformed = tv.fit_transform(my_dataframe['text_clean'])\n",
    "\n",
    "# Create a DataFrame with these features\n",
    "tv_df = pd.DataFrame(tv_transformed.toarray(), \n",
    "                     columns=tv.get_feature_names())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ngram N-gram n gram\n",
    "cv_trigram_vec = CountVectorizer(max_features=100, \n",
    "                                 stop_words='english', \n",
    "                                 ngram_range=(2,2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Most/top common words\n",
    "# Create a DataFrame of the features\n",
    "cv_tri_df = pd.DataFrame(cv_transformed.toarray(), \n",
    "                 columns=cv.get_feature_names())\n",
    "# Print the top 5 words in the sorted output\n",
    "print(cv_tri_df.sum().sort_values(ascending=False).head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
