{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset & Set variables\n",
    "dataset = pd.read_csv(\"Ads_CTR_Optimisation.csv\")\n",
    "\n",
    "n_items = 10\n",
    "\n",
    "n_trials = 10000\n",
    "\n",
    "sum_reward = [0] * n_items # Number of rewards of each item\n",
    "\n",
    "sum_selection = [0] * n_items # Number of selections of each item\n",
    "\n",
    "total_rewards = 0 # Total gained rewards\n",
    "\n",
    "items_selected = [] # a History contains the selected item at each N_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm Implementation\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    max_UCB = 0\n",
    "    # Randomly select first item and try it\n",
    "    selected_item = 0\n",
    "    for item in range(n_items):\n",
    "        # If current item has been choosen before -> calculate upper bound\n",
    "        if sum_selection[item] > 0 :\n",
    "            average_reward = sum_reward[item] / sum_selection[item]\n",
    "            delta = math.sqrt( 2 * (math.log(trial + 1) / sum_selection[item]  ) )\n",
    "            upper_bound = average_reward + delta\n",
    "        # If current item has never been choosen -> \n",
    "        # use a big number to break the later condition to select that item\n",
    "        else :\n",
    "            upper_bound = 10e100\n",
    "        if upper_bound > max_UCB :\n",
    "            # Update max upper bound & keep selected item index\n",
    "            max_UCB = upper_bound\n",
    "            selected_item = item\n",
    "    # Update selected item's data\n",
    "    # Add a reward(1) or punishment(0) to selected item\n",
    "    reward = dataset.values[trial, selected_item]\n",
    "    sum_reward[selected_item] += reward\n",
    "    total_rewards += reward\n",
    "    # Add 1 to selected times of that item\n",
    "    sum_selection[selected_item] += 1\n",
    "    # Keep a history of which item is selected\n",
    "    items_selected.append(selected_item + 1) # +1 because selected_item is index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.hist(items_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most selected item (as value, not as index)\n",
    "top_item = np.bincount(np.array(items_selected)).argmax()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
